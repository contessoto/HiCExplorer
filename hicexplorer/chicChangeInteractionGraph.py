import argparse
import sys
import errno
import os
import math
from multiprocessing import Process, Queue
from scipy.sparse import coo_matrix, dia_matrix, lil_matrix, csr_matrix

import time
import logging
log = logging.getLogger(__name__)

import numpy as np
from scipy import stats
import h5py
import networkx as nx
from holoviews.plotting.util import process_cmap
import matplotlib.pyplot as plt
import tarfile

import io
import tarfile
from contextlib import closing
from pyvis.network import Network
import scipy.sparse as sp

import hicmatrix.HiCMatrix as hm
from intervaltree import IntervalTree, Interval

from hicexplorer import utilities
from hicexplorer._version import __version__
from .lib import Viewpoint


def parse_arguments(args=None):
    parser = argparse.ArgumentParser(add_help=False,
                                     formatter_class=argparse.RawDescriptionHelpFormatter,
                                     description="""
chicCreateInteractionGraph computes the network of a reference point with its regions of interest. To add a region to the graph, a second file containing the chromatin status and peak is required.
For each interaction it is checked if it is matching the position of a peak; moreover, the chromatin status is used.
"""
                                     )

    parserRequired = parser.add_argument_group('Required arguments')

    parserRequired.add_argument('--graphFiles', '-gf',
                                help='path to the graph files. Please use only the graph as generated by chicCreateInteractionGraph',
                                required=True,
                                nargs=2)

    # parserRequired.add_argument('--peakFile', '-tf',
    #                             help='Peak file containing the peaks and chromatin status based on ATAC-Seq data.'
    #                             )
    # parserRequired.add_argument('--referencePoints', '-rp', help='Reference point file. Needs to be in the format: \'chr 100\' for a '
    #                             'single reference point or \'chr 100 200\' for a reference region and with a single reference point per line',
    #                             required=True)

    parserOpt = parser.add_argument_group('Optional arguments')

    parserOpt.add_argument('--outFileName', '-o',
                           help='Output file for the graph file'
                           ' (Default: %(default)s).',
                           required=False,
                           default='interactionGraph.hdf5')
    parserOpt.add_argument('--plotsFileName', '-po',
                           help='Output tar.gz of the plotted graph files.'
                           ' (Default: %(default)s).',
                           required=False,
                           default='plotInteractionGraphs.tar.gz')
    parserOpt.add_argument('--outputFormat', '-format',
                           help='Output format of the plot'
                           ' (Default: %(default)s).',
                           required=False,
                           default='png')
    parserOpt.add_argument('--threads', '-t',
                           help='Number of threads (uses the python multiprocessing module)'
                           ' (Default: %(default)s).',
                           required=False,
                           default=4,
                           type=int
                           )
    parserOpt.add_argument("--help", "-h", action="help",
                           help="show this help message and exit")
    parserOpt.add_argument('--version', action='version',
                           version='%(prog)s {}'.format(__version__))
    return parser

def readGraphFile(pGraphFile):
    graphHDF5Object = h5py.File(pGraphFile, 'r')

    csr_matrix_interaction_data = np.array(graphHDF5Object["csr_matrix_interaction_data"][:])
    csr_matrix_interaction_indices = np.array(graphHDF5Object["csr_matrix_interaction_indices"][:])
    csr_matrix_interaction_indptr = np.array(graphHDF5Object["csr_matrix_interaction_indptr"][:])

    csr_matrix_state_data = np.array(graphHDF5Object["csr_matrix_state_data"][:])
    csr_matrix_state_indices = np.array(graphHDF5Object["csr_matrix_state_indices"][:])
    csr_matrix_state_indptr = np.array(graphHDF5Object["csr_matrix_state_indptr"][:])

    peak_types_list = np.array(graphHDF5Object["peak_types_list"][:])
    reference_point_list = np.array(graphHDF5Object["reference_point_list"][:])
    peak_list = np.array(graphHDF5Object["peak_list"][:])

    # csr_matrix((data, indices, indptr), [shape=(M, N)])
    csr_matrix_interaction = csr_matrix((csr_matrix_interaction_data, csr_matrix_interaction_indices, csr_matrix_interaction_indptr))
    csr_matrix_state = csr_matrix((csr_matrix_state_data, csr_matrix_state_indices, csr_matrix_state_indptr))

    peak_dict = {}
    reference_point_dict = {}
    peak_type_dict = {}

    peak_dict_inverse = {}
    reference_point_dict_inverse = {}
    peak_type_dict_inverse = {}

    for i, peak in enumerate(peak_list):
        peak_dict[i] = peak
        peak_dict_inverse[peak] = i
    for i, graph in enumerate(reference_point_list):
        reference_point_dict[i] = graph
        reference_point_dict_inverse[graph] = i
    for i, peak_type in enumerate(peak_types_list):
        peak_type_dict[i + 1] = peak_type
        peak_type_dict_inverse [peak_type] = i + 1
    

    peak_type_dict[0] = 'None'
    peak_type_dict_inverse['None'] = 0
    
    # for 
    # csr_matrix_interaction_data
    # csr_matrix_interaction_indices
    # csr_matrix_interaction_indptr
    # csr_matrix_state_data
    # csr_matrix_state_indices
    # csr_matrix_state_indptr
    # peak_types_list
    # reference_point_list
    # peak_list
    log.debug('len(peak_dict) {}'.format(len(peak_dict)))
    log.debug('len(peak_type_dict) {}'.format(len(peak_type_dict)))

    return csr_matrix_interaction, csr_matrix_state, peak_dict, reference_point_dict, peak_type_dict, peak_dict_inverse, reference_point_dict_inverse, peak_type_dict_inverse

def equalizeGraphs(pGraphOne, pGraphTwo, pReferencePointDictOne, pReferencePointDictTwo):

    reference_point_seen = set()
    graph_one = None
    graph_two = None
    graph_one_reference_id_relation_inverse = {}
    graph_two_reference_id_relation_inverse = {}

    counter = 0
    for reference_point in pReferencePointDictOne:
        if reference_point in pReferencePointDictTwo:
            id_one = pReferencePointDictOne[reference_point]
            id_two = pReferencePointDictTwo[reference_point]
            if graph_one is None:
                graph_one = pGraphOne.getrow(id_one)
            else:
                graph_one = sp.vstack([graph_one, pGraphOne.getrow(id_one)])
            graph_one_reference_id_relation_inverse[reference_point] = counter
            if graph_two is None:
                graph_two = pGraphOne.getrow(id_one)
            else:
                graph_two = sp.vstack([graph_two, pGraphTwo.getrow(id_two)])
            graph_two_reference_id_relation_inverse[reference_point] = counter

            counter += 1
            
        else:
            id_one = pReferencePointDictOne[reference_point]
            # id_two = pReferencePointDictTwo[reference_point]
            if graph_one is None:
                graph_one = pGraphOne.getrow(id_one)
            else:
                graph_one = sp.vstack([graph_one, pGraphOne.getrow(id_one)])
            graph_one_reference_id_relation_inverse[reference_point] = counter
            if graph_two is None:
                graph_two = csr_matrix(pGraphOne.getrow(id_one).shape)
            else:
                graph_two = sp.vstack([graph_two, csr_matrix(pGraphOne.getrow(id_one).shape)])
            graph_two_reference_id_relation_inverse[reference_point] = counter

            counter += 1
        reference_point_seen.add(reference_point)
    for reference_point in pReferencePointDictTwo:
        if reference_point in reference_point_seen:
            continue
        else:
            id_two= pReferencePointDictTwo[reference_point]
            # id_two = pReferencePointDictTwo[reference_point]
            if graph_two is None:
                graph_two = pGraphTwo.getrow(id_two)
            else:
                graph_two = sp.vstack([graph_two, pGraphTwo.getrow(id_two)])
            graph_two_reference_id_relation_inverse[reference_point] = counter

            if graph_one is None:
                graph_one = csr_matrix(pGraphTwo.getrow(id_two).shape)
            else:
                graph_one = sp.vstack([graph_one, csr_matrix(pGraphTwo.getrow(id_two).shape)])
            graph_one_reference_id_relation_inverse[reference_point] = counter

            counter += 1
        reference_point_seen.add(reference_point)

    graph_one_reference_id_relation = {}
    graph_two_reference_id_relation = {}

    for i, relation in enumerate(graph_one_reference_id_relation_inverse):
        graph_one_reference_id_relation[i] = relation
    
    for i, relation in enumerate(graph_two_reference_id_relation_inverse):
        graph_two_reference_id_relation[i] = relation
    return graph_one, graph_two, graph_one_reference_id_relation, graph_two_reference_id_relation, graph_one_reference_id_relation_inverse, graph_two_reference_id_relation_inverse
        

def main(args=None):
    args = parse_arguments().parse_args(args)
    # viewpointObj = Viewpoint()

    fileList = []
    # read hdf file
    graphOneHDF5Object = h5py.File(args.graphFiles[0], 'r')
    graphTwoHDF5Object = h5py.File(args.graphFiles[1], 'r')

    fileTypeOne = graphOneHDF5Object.attrs['type']
    fileTypeTwo = graphTwoHDF5Object.attrs['type']

    graphOneHDF5Object.close()
    graphTwoHDF5Object.close()

    if fileTypeOne != 'graph' and fileTypeTwo != 'graph':
        log.error("Wring file type! Exit.")
        exit(1)
    
    csr_matrix_interaction_one, csr_matrix_state_one, peak_dict_one, reference_point_dict_one, peak_type_dict_one, \
    peak_dict_inverse_one, reference_point_dict_inverse_one, peak_type_dict_invers_one = readGraphFile(args.graphFiles[0])
    csr_matrix_interaction_two, csr_matrix_state_two, peak_dict_two, reference_point_dict_two, peak_type_dict_two, \
    peak_dict_inverse_two, reference_point_dict_inverse_two, peak_type_dict_invers_two = readGraphFile(args.graphFiles[1])

    csr_matrix_state_one, csr_matrix_state_two, reference_point_dict_one, reference_point_dict_two, reference_point_dict_inverse_one, reference_point_dict_inverse_two = equalizeGraphs(csr_matrix_state_one, csr_matrix_state_two, reference_point_dict_inverse_one, reference_point_dict_inverse_two)
    log.debug('shape one: {}'.format(csr_matrix_state_one.shape))
    log.debug('shape two: {}'.format(csr_matrix_state_two.shape))

    # substract status matrices from each other
    # if the status was the same, the element is now 0
    # if it changed, the element is != 0
    change_state_matrix = csr_matrix_state_one - csr_matrix_state_two
    change_state_matrix.eliminate_zeros()

    row, features = change_state_matrix.nonzero()

    reference_point_status_change = {}
    for i, row_ in enumerate(row):

        status_old = csr_matrix_state_one[row_, features[i]]
        status_new = csr_matrix_state_two[row_, features[i]]

        # try:
        if row_ in reference_point_status_change:
            reference_point_status_change[row_].append([peak_dict_one[features[i]],peak_type_dict_one[status_old], peak_type_dict_two[status_new]])
        else:
            reference_point_status_change[row_] = [[peak_dict_one[features[i]], peak_type_dict_one[status_old], peak_type_dict_two[status_new]]]
        # except:
        #     log.debug("row_ {}".format(row_))
        #     log.debug('features[i] {}'.format(features[i]))

        #     # log.debug('peak_dict_one {}'.format(peak_dict_one) )
        #     log.debug('peak_type_dict_one[status_old] {}'.format(peak_type_dict_one[status_old]))
        #     log.debug('peak_type_dict_two[status_new] {}'.format(peak_type_dict_two[status_new]))
        
    with tarfile.open(args.outFileName, "w:gz") as tar:

        for row_ in reference_point_status_change:

            file_name = reference_point_dict_one[row_].decode("utf-8") + '.txt'
            # log.debug('file_name {}'.format(file_name))
            # if (args.oneTargetFile and fileType == 'target') or (args.oneSignificantFile and fileType == 'significant') or (args.oneDifferentialFile and fileType == 'differential'):
                # if fileType == 'target':
                #     file_name = 'targets.tsv'
                # elif fileType == 'significant':
                #     file_name = 'significant.tsv'
                # elif fileType == 'differential':
                #     file_name = 'differential.tsv'
            
            # file_content_string_all = ''
            # for i, file_content_string in enumerate(thread_data):

            #     file_content_string_all += file_content_string

            # file_content_string_all = file_content_string_all.encode('utf-8')
            file_content_string_all = ''
            file_content_string_all += str(reference_point_dict_one[row_].decode("utf-8")) + '\n'

            file_content_string_all += "Peak\tStatus old\t Status new\n"

            for peak_change in reference_point_status_change[row_]:
                # line = 
                peak_change = [item if isinstance(item, str) else item.decode("utf-8") for item in peak_change ]

                file_content_string_all += "\t".join(peak_change) +'\n'

            tar_info = tarfile.TarInfo(name=file_name)
            tar_info.mtime = time.time()
            file_content_string_all = file_content_string_all.encode('utf-8')
            tar_info.size = len(file_content_string_all)
            file = io.BytesIO(file_content_string_all)
            tar.addfile(tarinfo=tar_info, fileobj=file)

        # with open('test124.txt', 'w') as file:
        #     file.write(str(reference_point_dict_one[row_].decode("utf-8")) + '\n')

        #     file.write("Peak\tStatus old\t Status new\n")

        #     for peak_change in reference_point_status_change[row_]:
        #         # line = 
        #         peak_change = [item if isinstance(item, str) else item.decode("utf-8") for item in peak_change ]

        #         file.write("\t".join(peak_change) +'\n')

        # exit(1)



